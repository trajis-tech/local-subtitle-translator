# Trajis SmartSRT (Modelos Port√°tiles, Sin Conexi√≥n)

Trajis SmartSRT ejecuta una canalizaci√≥n de traducci√≥n de subt√≠tulos local usando **llama-cpp-python**.
Est√° dise√±ado para ser **port√°til**: todas las dependencias viven dentro de esta carpeta.

‚úÖ **Offline-first**: ejecute `install.bat` (Windows) o `./install.sh` (Linux/macOS) **una vez** con red para descargar e instalar todo; luego use `start.bat` o `./start.sh` para **arranque offline** cuando quiera.

‚ùó **Los modelos NO se descargan autom√°ticamente.** Debe descargar manualmente los archivos GGUF y colocarlos en `./models/`.

---

## Resumen de la Canalizaci√≥n de Traducci√≥n

La canalizaci√≥n de traducci√≥n se divide en **6 ejecuciones** (A‚ÜíB‚ÜíC/D‚ÜíE‚ÜíF), ejecutadas secuencialmente. **Brief √∫nico**: un solo archivo actual `./work/brief.jsonl` se actualiza en cada etapa; antes de C/D/E se copia a `brief_v1.jsonl` / `brief_v2.jsonl` / `brief_v3.jsonl` (snapshots).

- **Run A**: An√°lisis de emoci√≥n/tono de audio (todas las l√≠neas de subt√≠tulos)
  - Extrae segmentos de audio del video para cada subt√≠tulo
  - Analiza emoci√≥n, tono, intensidad y estilo de habla
  - Los resultados se guardan en `./work/audio_tags.jsonl`
  - **Nota**: El modelo de audio est√° **preempaquetado** y **estrechamente acoplado** con el c√≥digo. **NO lo modifique ni reemplace.**

- **Run B**: El modelo principal genera el brief de traducci√≥n (todas las l√≠neas de subt√≠tulos)
  - Usa el modelo de razonamiento principal (GGUF, llama-cpp-python) para generar gu√≠a de traducci√≥n.
  - Entrada: Subt√≠tulo en ingl√©s + una l√≠nea de contexto anterior y siguiente + etiquetas de audio (todo en ingl√©s).
  - Salida: JSON ‚Äî **todo en ingl√©s** (neutral): `meaning_tl`, `draft_tl`, `tl_instruction`, `idiom_requests`, `ctx_brief`, **`referents`**, **`tone_note`**, **`scene_brief`**, y opcionalmente **`disambiguation_note`**, **`rewrite_guidance`**. **Un need por etapa**: v1 solo **`need_vision`** (booleano). Opcional: `transliteration_requests`, `omit_sfx`; `reasons` (incluye PACK para Run F).
  - Los resultados se guardan en `./work/brief.jsonl` (brief actual √∫nico).

- **Run C**: Fallback de visi√≥n de un solo fotograma (opcional, activado condicionalmente)
  - Se activa cuando **`need_vision === true`** (del brief actual).
  - Antes de actualizar: copiar `brief.jsonl` ‚Üí `brief_v1.jsonl`. Extrae un fotograma en el punto medio del rango de tiempo del subt√≠tulo; el modelo de visi√≥n analiza escena/personajes/acciones.
  - Regenera el brief con pista de un solo fotograma ‚Üí actualiza `./work/brief.jsonl`. **Un need por etapa**: v2 solo **`need_multi_frame_vision`** (booleano) por √≠tem.

- **Run D**: Fallback de visi√≥n de m√∫ltiples fotogramas (opcional, activado condicionalmente)
  - Se activa cuando **`need_multi_frame_vision === true`** (del brief actual).
  - Antes de actualizar: copiar `brief.jsonl` ‚Üí `brief_v2.jsonl`. Extrae N fotogramas (configurable, predeterminado: 3) espaciados uniformemente; el modelo de visi√≥n analiza y fusiona descripciones.
  - Regenera el brief con pista de m√∫ltiples fotogramas ‚Üí actualiza `./work/brief.jsonl`. **Un need por etapa**: v3 solo **`need_more_context`** (booleano); usado por Run E (expansi√≥n de contexto).

- **Run E**: Expansi√≥n de contexto (condicional)
  - Antes de actualizar: copiar `brief.jsonl` ‚Üí `brief_v3.jsonl`. Para √≠tems con **`need_more_context === true`**, ejecuta stage2 con contexto **prev-3/next-3** y actualiza su brief; escribe `./work/brief.jsonl`. No hay salida del modelo en idioma objetivo; solo brief.

- **Run F**: Traducci√≥n final (todas las l√≠neas de subt√≠tulos)
  - Run F lee el **brief actual** (`brief.jsonl`, actualizado por E) y el PACK para producir los subt√≠tulos completos en el idioma objetivo y escribir el SRT. **Config**: `config.PipelineConfig.run_e_scheme` (por defecto `"full"`). **UI**: men√∫ desplegable Run F scheme. **Ejecuci√≥n**: `pipeline_runs.run_final_translate()`; salida: `items.translated_text` y `work_dir/final_translations.jsonl`. **Escritura SRT**: `app.py` alinea por `(round(start_ms), round(end_ms))`, conserva etiquetas `<i>` del original.
  - **Un modelo a la vez**: solo MAIN o LOCAL est√° cargado; el glosario se aplica solo en la salida.
  - **Robustez**: todas las llamadas chat pasan por **chat_dispatch**. Las peticiones heavy pueden ejecutarse en un subproceso one-shot; en fallo, fallback in-process.

### Esquemas Run F (elegir por fuerza del modelo principal / modelo de localizaci√≥n)

En la UI seleccione el esquema en el men√∫ **Run F scheme**. Opciones: `full` | `main_led` | `local_led` | `draft_first` (valor inv√°lido hace fallback a `full`).

| Scheme | Cu√°ndo usar (principal/local) | Phase1 (origen borrador) | Phase2 (pulido) |
|--------|---------------------|------------------------|-----------------|
| **Full** | Principal fuerte, local fuerte | Traducci√≥n por grupos MAIN ‚Üí draft_map | Pulido LOCAL |
| **MAIN-led** | Principal fuerte, local d√©bil | Traducci√≥n por grupos MAIN ‚Üí draft_map | ninguno |
| **LOCAL-led** | Principal d√©bil, local fuerte | PACK draft_tl ‚Üí draft_map; opcional LOCAL rellenar slots idiom | Pulido LOCAL |
| **Draft-first** | Principal d√©bil, local d√©bil | PACK draft_tl ‚Üí draft_map; opcional LOCAL rellenar slots idiom | ninguno |

- **Full**: Fase 1 ‚Äî cargar MAIN (reason), construir grupos de oraciones, dividir por `group_translate_max_segments` (por defecto 4); por cada chunk llamar `stage_main_group_translate`; **se acepta salida MAIN parcial** (emparejar por **id**; segmentos faltantes usan PACK draft_tl o en_text). Fase 2 ‚Äî cargar LOCAL, `local_polish` por chunks (`local_polish_chunk_size`, por defecto 60); solo claves de la petici√≥n que pasen comprobaciones de longitud/contaminaci√≥n se aplican a draft_map. Final: glosario + strip_punctuation ‚Üí `translated_text`.
- **MAIN-led**: Fase 1 ‚Äî igual que Full (traducci√≥n por grupos MAIN ‚Üí draft_map). Fase 2 ‚Äî **omitida**. Final: glosario + strip_punctuation.
- **LOCAL-led**: Sin MAIN. `draft_map = _build_draft_map_from_pack(...)`. Si alg√∫n √≠tem tiene `idiom_requests`, cargar LOCAL, llamar `stage3_suggest_local_phrases` por l√≠nea, rellenar slots con `_fill_draft_with_suggestions` y actualizar draft_map. Luego cargar LOCAL y ejecutar `local_polish` por chunks. Final: glosario + strip_punctuation.
- **Draft-first**: Sin MAIN. Construir draft_map solo desde PACK; si hay idiom_requests, cargar LOCAL, obtener sugerencias y rellenar; **sin** pulido. Los modelos de localizaci√≥n d√©biles usan prompts **STRICT** y fallback raw_decode para evitar errores de formato.

**Alineaci√≥n**: Toda la alineaci√≥n en Run F es por **sub_id** y **marcas de tiempo (start_ms, end_ms)**; nunca por √≠ndice de lista.

**Pol√≠tica de idioma (sin mezclar entre etapas)**:
- **Run A‚ÄìE**: Todos los prompts y todas las salidas del modelo son **solo en ingl√©s**. Run A (audio), Run B/C/D (brief) y Run E (expansi√≥n de contexto) no reciben ni producen texto en idioma objetivo; el brief es ingl√©s neutro para que Run F traduzca desde una √∫nica interfaz en ingl√©s.
- **Run F**: Todas las **instrucciones (prompts) en ingl√©s**; la entrada a los modelos principal y de localizaci√≥n es **ingl√©s** (segmentos, tl_instruction, contexto). Solo la **salida del modelo** (segment_texts[].text, l√≠neas pulidas, sugerencias de frases) est√° en el **idioma objetivo**.
- **Aplicaci√≥n**: La salida del brief de Run B se sanitiza (p. ej. `tl_instruction` debe ser solo ingl√©s). Run F usa `_tl_instruction_for_run_e()` para que la etapa de traducci√≥n siempre obtenga la locale objetivo correcta.

**Roles de prompt** (`model_prompts.csv`): MAIN (main_group_translate) se centra en el **ORIGEN (SOURCE)**; localizaci√≥n fuerte (p. ej. Llama-Breeze2-8B) se centra en el **idioma objetivo**, naturalizar/pulir; localizaci√≥n d√©bil (p. ej. Breeze-7B, custom-localization) usa formato **STRICT**; en fallo de parse se usa raw_decode para extraer el primer `{...}`.

**Transliteraci√≥n (Èü≥Ë≠Ø)**: Los nombres o t√©rminos que deben transliterarse en el idioma objetivo son tarea del **modelo de localizaci√≥n**; el **modelo principal** (Run B) los propone en PACK como `transliteration_requests` (array de cadenas). Run F Fase 2 (local_polish) recibe estos t√©rminos y a√±ade al prompt de pulido ¬´Transliterate (Èü≥Ë≠Ø) in target language for these terms: ‚Ä¶¬ª para que LOCAL emita las formas transliteradas.

**CC / SFX (ÁãÄËÅ≤Ë©û)**: El **modelo principal** (Run B) filtra efectos de sonido y onomatopeyas (p. ej. `[laughter]`, `[sigh]`, `*gasps*`). Puede poner `omit_sfx: true` y `draft_tl` vac√≠o para l√≠neas solo SFX; para di√°logo+SFX pone solo el di√°logo en `draft_tl`. Run F aplica omit_sfx tras construir draft_map, por lo que esas l√≠neas quedan con salida vac√≠a.

**Config Run F** (`config.py`): `run_e_scheme` (UI: Run F scheme), `group_translate_max_segments` (por defecto 4), `local_polish_chunk_size` (por defecto 60), `strip_punctuation`, `strip_punctuation_keep_decimal`, `strip_punctuation_keep_acronym`.

### Caracter√≠sticas Principales

- **Carga de Modelo √önico**: Solo se carga un modelo a la vez (audio, raz√≥n, visi√≥n o traducci√≥n)
- **Reanudable**: Cada ejecuci√≥n guarda resultados intermedios en `./work/` (formato JSONL)
- **Resistente a Errores**: Si falla la visi√≥n/audio, la canalizaci√≥n contin√∫a con el mejor brief disponible
- **Seguimiento de Progreso**: La barra de progreso muestra el paso actual y el porcentaje de finalizaci√≥n

---

## Entrada de video (nota sobre FFmpeg)

El componente **Video** incorporado de Gradio realiza procesamiento del lado del servidor que requiere un ejecutable externo **`ffmpeg`**.
Si `ffmpeg` no est√° disponible, puede obtener errores como **"Executable 'ffmpeg' not found"**.

Para mantener este proyecto **completamente port√°til** (sin instalaciones a nivel del sistema), este repositorio usa una entrada **File** para el video en su lugar.

- Necesita un archivo de video para **Run A (audio)** y **Run C/D (visi√≥n)**.
- Se usa OpenCV (opencv-python) para capturar fotogramas para Vision, y ffmpeg se usa para extraer segmentos de audio.
- **ffmpeg**: **Windows** ‚Äì si ffmpeg no est√° en PATH, `install.bat` descarga una versi√≥n port√°til en `runtime\ffmpeg`. **Linux / macOS** ‚Äì `install.sh` solo comprueba ffmpeg en PATH; inst√°lelo manualmente y vea **FFMPEG_INSTALL.md** si falta.

Si est√° usando un zip anterior que a√∫n usa el componente Video, actualice al zip m√°s reciente o instale FFmpeg y agr√©guelo a PATH.

## Instalaci√≥n y arranque (offline-first)

Este proyecto est√° pensado para **uso offline**: ejecute **install** una vez (con red), luego use **start** cuando quiera (sin red).

**‚ö†Ô∏è IMPORTANTE - Usuarios de GPU NVIDIA:**
- **Instale CUDA Toolkit 12.9** (o 12.x) **ANTES** de ejecutar `install.bat` / `install.sh`
- Descarga: https://developer.nvidia.com/cuda-downloads
- La rueda precompilada de llama-cpp-python requiere que CUDA est√© instalado primero para la aceleraci√≥n por GPU

1. Extraiga esta carpeta en cualquier lugar (ejemplo: `G:\Trajis SmartSRT`).

2. **Instalar (una vez, con red)** ‚Äî descarga e instala todo:
   - **Windows**: doble clic en `install.bat` ‚Üí Python port√°til, venv, todas las dependencias Python (base + audio Run A + v√≠deo), opcional CUDA PyTorch si hay GPU, ffmpeg en `runtime\ffmpeg` si no est√° en PATH, modelo de audio Run A en `models\audio`, rueda precompilada llama-cpp-python, config, BOM. Los modelos GGUF son manuales (v√©ase abajo).
     - **Uso estimado de disco tras instalar**: ~6-8 GB (solo CPU: ~4-5 GB; con CUDA PyTorch + ffmpeg: ~6-8 GB)
   - **Linux / macOS**: ejecute `./install.sh` (misma idea: .venv, deps, modelo de audio, rueda precompilada llama-cpp-python, config, BOM). Si hace falta: `chmod +x install.sh`
     - **Uso estimado de disco tras instalar**: ~4-5 GB (excluyendo Python del sistema y ffmpeg)

3. **Arrancar (offline)** ‚Äî sin descargas, sin red:
   - **Windows**: doble clic en `start.bat` ‚Üí comprueba .venv y archivos de modelo, luego lanza la UI.
   - **Linux / macOS**: ejecute `./start.sh`. Si hace falta: `chmod +x start.sh`

- **Desinstalar**: ejecute `uninstall.bat` (Windows) o `./uninstall.sh` (Linux/macOS) para eliminar entorno, venv y cach√©s dentro de esta carpeta. Si hace falta: `chmod +x uninstall.sh`

**Soporte de GPU:**

- **GPUs NVIDIA**: soporte CUDA 12.x (CUDA 12.9 recomendado; series RTX 20/30/40/50, serie GTX 16 y m√°s recientes)
- **GPUs AMD**: soporte ROCm (experimental, requiere configuraci√≥n manual)
- **GPUs Intel Arc**: soporte oneAPI (experimental, requiere configuraci√≥n manual)
- **CPU**: optimizado para CPUs Intel (no requiere conjunto de instrucciones AVX-512), funciona en todos los procesadores x86-64 modernos

**Opcional ‚Äì instalar solo dependencias de audio (Linux / macOS):**

- Ejecutar `install.bat` o `install.sh` ya instala las dependencias de Run A (audio). Use `./scripts/install_audio_deps.sh` solo si necesita reinstalar dependencias de audio (torch, transformers, soundfile, scipy) sin hacer la instalaci√≥n completa. Requiere Python 3 y opcionalmente un `.venv` activo.

Todo permanece dentro de esta carpeta (port√°til/aislado).

---

## Compatibilidad de modelos y estructura de carpetas (requerido)

Todos los modelos de **texto y visi√≥n** que usa esta aplicaci√≥n deben ser **GGUF** y compatibles con **llama-cpp-python**. Usted proporciona los archivos; la aplicaci√≥n no los descarga.

Cree y use esta estructura de carpetas:

```
models/
  main/     ‚Üê Modelo de razonamiento principal (Run B); uno o m√°s archivos .gguf
  local/    ‚Üê Modelo de localizaci√≥n/traducci√≥n (Run E); uno o m√°s archivos .gguf
  vision/   ‚Üê Modelo de visi√≥n opcional (Run C/D); .gguf principal + mmproj .gguf
  audio/    ‚Üê Modelo de audio Run A (descargado por el script de instalaci√≥n o en la primera ejecuci√≥n)
```

### Compatibilidad

- **Modelos principal y de localizaci√≥n**: Cualquier modelo **GGUF** que funcione con llama-cpp-python (modelos instruct/chat con plantilla de chat). Coloque los archivos en `./models/main/` y `./models/local/` respectivamente. Si la cuantizaci√≥n est√° **fragmentada** (varios .gguf), descargue **todos los fragmentos** y col√≥quelos en la misma carpeta.
- **Modelos de visi√≥n (opcional)**: Cualquier modelo de **visi√≥n GGUF** soportado por llama-cpp-python (modelo principal + mmproj). Coloque ambos archivos en `./models/vision/`. La aplicaci√≥n detecta el tipo por el nombre del archivo. Puede fijar nombres exactos en `config.json` en `vision.text_model` y `vision.mmproj_model`.
- **Audio (Run A)**: El modelo de emoci√≥n Run A se descarga de Hugging Face Hub en la primera ejecuci√≥n (sin GGUF local). Usa Transformers `audio-classification`; dependencias: `torch`, `transformers`, `soundfile`, `scipy`.

### Par√°metros y cuantizaci√≥n (gu√≠a gen√©rica)

- **Cuantizaci√≥n**: Cuantos m√°s ligeros (p. ej. **Q4_K_M**) menos VRAM y m√°s r√°pido; m√°s pesados (**Q5_K_M**, **Q6_K**, **Q8_0**) mejor calidad pero m√°s VRAM y disco. Elija seg√∫n su GPU/RAM.
- **Tama√±o del modelo**: M√°s par√°metros (p. ej. 14B, 7B) requieren m√°s VRAM y RAM. Los modelos se cargan **uno a la vez**, as√≠ que la VRAM la define el **modelo √∫nico m√°s grande** que use.
- **Contexto**: Un `n_ctx_*` mayor (p. ej. 8192) mejora el contexto largo pero aumenta la VRAM (cach√© KV). Si hay OOM, reduzca `n_ctx_*` o `n_gpu_layers_*`.

### Puntos de partida sugeridos para config.json (ajuste seg√∫n su hardware)

- **16 GB VRAM**: `n_ctx_reason=8192`, `n_ctx_translate=4096`, `n_gpu_layers_reason=60`, `n_gpu_layers_translate=60`
- **12 GB VRAM**: `n_ctx_reason=4096`, `n_ctx_translate=2048`, `n_gpu_layers_reason=50`, `n_gpu_layers_translate=50`
- **8 GB VRAM**: `n_ctx_reason=2048`, `n_ctx_translate=2048`, `n_gpu_layers_reason=35`, `n_gpu_layers_translate=35`
- **Solo CPU / poca RAM**: Prefiera Q4_K_M (o m√°s ligero) y contexto peque√±o; reduzca `n_gpu_layers_*` o p√≥ngalo a 0 para usar solo CPU.

---

## config.json

Cuando ejecuta `install.bat` (o `install.sh`), se ejecuta `scripts/plan_models.py` para crear `config.json` si no existe. `start.bat` / `start.sh` no crean config; solo arrancan la aplicaci√≥n.
En uso normal **no es necesario mantener config.json**; los modelos se detectan desde `./models`. Ed√≠telo solo si necesita ajustes avanzados (VRAM, tama√±os de lote, fallbacks).

---

## Directorio de Trabajo (Resultados Intermedios)

Todos los resultados intermedios se guardan en el directorio `./work/` en formato JSONL:

- `audio_tags.jsonl` - Resultados de Run A (an√°lisis de emoci√≥n/tono de audio)
- `brief.jsonl` - Brief actual (Run B escribe; C/D/E actualizan; Run F lee)
- `brief_v1.jsonl` - Snapshot antes de Run C (copia antes de que C actualice)
- `brief_v2.jsonl` - Snapshot antes de Run D
- `brief_v3.jsonl` - Snapshot antes de Run E (expansi√≥n de contexto)
- `vision_1frame.jsonl` - Resultados de Run C (an√°lisis de visi√≥n de un solo fotograma)
- `vision_multiframe.jsonl` - Resultados de Run D (an√°lisis de visi√≥n de m√∫ltiples fotogramas)
- `final_translations.jsonl` - Resultados de Run F (texto traducido final, nuevo formato)

**Compatibilidad de Formato JSONL:**

La canalizaci√≥n admite tanto el **formato antiguo** (usando `idx` para alineaci√≥n) como el **formato nuevo** (usando `sub_id` para alineaci√≥n):

- **Formato antiguo**: Usa `idx` (√≠ndice entero) para identificar l√≠neas de subt√≠tulos
  - Ejemplo: `{"idx": 0, "start_ms": 1000, "end_ms": 2000, ...}`
- **Formato nuevo**: Usa `sub_id` (identificador √∫nico basado en hash) para garantizar la alineaci√≥n de datos
  - Ejemplo: `{"sub_id": "a1b2c3d4_0", "start_ms": 1000, "end_ms": 2000, ...}`
  - `sub_id` se genera a partir de `hash(start_ms, end_ms, text_raw)` para garantizar la consistencia entre runs

La canalizaci√≥n detecta autom√°ticamente el formato y maneja la conversi√≥n cuando es necesario. Los nuevos runs usar√°n el formato `sub_id` para garantizar una mejor integridad de datos.

**Funcionalidad de reanudaci√≥n**: Si existe un archivo JSONL y tiene el n√∫mero correcto de entradas, la canalizaci√≥n lo cargar√° autom√°ticamente y omitir√° ese run. La canalizaci√≥n admite reanudaci√≥n tanto desde el formato antiguo (`idx`) como desde el nuevo (`sub_id`).

**Reanudaci√≥n manual**: Puede eliminar archivos JSONL espec√≠ficos para volver a ejecutar solo esos pasos.

---

## Uso de la UI

1. **Subir archivos**: Video (MKV/MP4) y SRT (subt√≠tulos en ingl√©s)
2. **Seleccionar modo de ejecuci√≥n**: `all` (A‚ÜíB‚Üí(C/D)‚ÜíE‚ÜíF, predeterminado) | **A** (audio) | **B** (brief) | **C** (visi√≥n 1 fotograma) | **D** (visi√≥n m√∫ltiples fotogramas) | **E** (expansi√≥n de contexto) | **F** (traducci√≥n)
3. **Run F scheme** (men√∫ desplegable): elija por fuerza del modelo principal / de localizaci√≥n ‚Äî **Full** | **MAIN-led** | **LOCAL-led** | **Draft-first**. V√©ase **Esquemas Run F** en Resumen de la Canalizaci√≥n.
4. **Fallbacks opcionales** (casillas en la UI):
   - **Habilitar fallback de visi√≥n (Run C/D)**: cuando est√© marcado y el brief tenga **need_vision** / **need_multi_frame_vision**, se ejecuta visi√≥n de un fotograma (C) o m√∫ltiples (D) y se actualiza el brief. Requiere modelo de visi√≥n GGUF local.
   - **Habilitar fallback de expansi√≥n de contexto (Run E)**: cuando est√© marcado, los √≠tems con **need_more_context** obtienen contexto prev-3/next-3 y brief actualizado antes de Run F. Recomendado.
   - **Max frames per subtitle (Run D)** / **Frame offsets**: n√∫mero y posiciones de fotogramas (predeterminado: 1‚Äì4).
5. **Hacer clic en "üöÄ Translate"** y monitorear el progreso
6. **Descargar** el archivo SRT traducido cuando est√© completo
7. **Restablecer**: Haga clic en **"Reset"** para borrar todas las entradas, salidas y registro y restaurar los valores predeterminados para comenzar una nueva traducci√≥n

**Detalles de la UI**: El panel de registro muestra las **entradas m√°s recientes arriba**. `model_prompts.csv` se lee/escribe en UTF-8 con BOM; `start.bat` / `start.sh` ejecutan `ensure_csv_bom.py` al iniciar para mantener la codificaci√≥n correcta.

---

## Personalizaci√≥n de Prompts de Modelo (model_prompts.csv)

La canalizaci√≥n de traducci√≥n usa prompts definidos en `model_prompts.csv`. El prompt de cada modelo se empareja autom√°ticamente por **nombre de archivo del modelo** (coincidencia de subcadena que no distingue may√∫sculas y min√∫sculas). El archivo debe estar en **UTF-8 con BOM**; `start.bat` y `start.sh` ejecutan `scripts/ensure_csv_bom.py` al iniciar para asegurarlo.

### Alineaci√≥n oficial de prompts del modelo

Los prompts est√°n dise√±ados para seguir el formato de chat **oficial** y las recomendaciones de cada familia de modelos, de modo que el comportamiento sea predecible y compatible:

- **Qwen2.5 (ChatML)**: Rol system + rol user; JSON Mode para salida estructurada. Las plantillas usan `chat_format=chatml` e instrucciones estrictas de ¬´solo JSON v√°lido, sin markdown¬ª seg√∫n el uso oficial de Qwen.
- **Gemma 2 (p. ej. TranslateGemma)**: **Sin rol system**; toda la instrucci√≥n va en el primer turno de user. El backend fusiona el contenido de system en el mensaje de user cuando `chat_format=gemma`, de modo que el modelo solo ve un turno de user.
- **Mistral / Llama 2 (p. ej. Breeze, Llama-Breeze2)**: Estilo `[INST]`; el system prompt se antepone al primer bloque `[INST]`. Se usa en los roles `local_polish` y `localization` con salida STRICT JSON cuando se requiere.
- **Vision (Moondream, LLaVA)**: Los prompts se aplican en c√≥digo por handler; el formato de chat se detecta autom√°ticamente por el nombre del archivo del modelo de visi√≥n. La salida es siempre descripci√≥n visual **en ingl√©s** √∫nicamente (no subt√≠tulos).

La columna **notes** del CSV documenta si el rol es ¬´Run A~D todo en ingl√©s¬ª o ¬´Run E: salida solo en idioma objetivo¬ª para que las filas personalizadas mantengan las mismas fronteras de idioma.

### Coincidencia de Nombre de Modelo

- **C√≥mo funciona**: La aplicaci√≥n extrae el nombre de archivo del modelo (p. ej., `my-main-model-q5_k_m.gguf`) y lo compara con la columna CSV `model_name`.
- **Regla de coincidencia**: Si el nombre de archivo **contiene** el CSV `model_name` (sin distinguir may√∫sculas y min√∫sculas), es una coincidencia.
  - Ejemplo: `my-main-model-q5_k_m.gguf` coincide con `my-main-model`
  - Ejemplo: `my-local-model-00001-of-00002.gguf` coincide con `my-local-model`
- **Qu√© completar**: Use una **subcadena √∫nica** que aparezca en el nombre de archivo de su modelo. Por lo general, el nombre del modelo base sin sufijo de cuantizaci√≥n funciona.

### Gu√≠a de Columnas CSV

| Columna | Descripci√≥n | Ejemplo |
|--------|-------------|---------|
| `model_name` | Subcadena para coincidir en el nombre de archivo (sin distinguir may√∫sculas y min√∫sculas) | `my-main-model` |
| `role` | `main` (Run B), `main_assemble` (Run E Stage4), `localization` (Run E), o `vision` (Run C/D) | `localization` |
| `source_language` | Idioma de entrada (generalmente `English`) | `English` |
| `target_language` | Idioma de salida (C√≥digo de localizaci√≥n: `en`, `zh-TW`, `zh-CN`, `ja-JP`, `es-ES`) | `zh-TW` |
| `chat_format` | Plantilla de chat del modelo (`chatml`, `llama-3`, `mistral-instruct`, `moondream`) | `chatml` |
| `system_prompt_template` | Prompt del sistema (definici√≥n de rol) | Ver ejemplos a continuaci√≥n |
| `user_prompt_template` | Prompt del usuario con marcadores de posici√≥n | Ver ejemplos a continuaci√≥n |
| `notes` | Descripci√≥n (ingl√©s) | `Localization model for Traditional Chinese (Taiwan)` |

### Marcadores de Posici√≥n

Use estos marcadores de posici√≥n en `user_prompt_template`:

**Marcadores de posici√≥n Run B (main):**
- `{line}` ‚Üí L√≠nea de subt√≠tulo en ingl√©s actual
- `{context}` ‚Üí Contexto completo (Prev-1, Current, Next-1, Prev-More, Next-More, Visual Hint)

**Marcadores de posici√≥n Run E (localization):**
- `{tl_instruction}`, `{requests_json}`, `{target_language}` (sugerencias de frases idiom√°ticas)

**Marcadores de posici√≥n Run E (main_assemble)** ‚Äì Stage4 ensamblado en una l√≠nea:
- `{target_language}`, `{line_en}`, `{ctx_brief}`, `{draft_prefilled}`, `{suggestions_json}`

**Marcadores de posici√≥n Run C/D (vision):**
- `{line}` ‚Üí L√≠nea de subt√≠tulo en ingl√©s actual

### Estilos de Prompt: Modelos Base vs Instruct

#### Modelos Base (No Instruct)
- **Caracter√≠sticas**: Prompts m√°s simples y directos sin formato de instrucci√≥n estructurado
- **Cu√°ndo usar**: Su modelo es un modelo base/completado (no ajustado para instrucciones)
- **Estilo**: Preguntas directas o descripciones de tareas simples
- **Ejemplo** (Run B):
  ```
  Analyze this subtitle line and explain what it really means in plain English.
  
  Subtitle: {line}
  Context: {context}
  
  Explain the meaning, including any idioms, jokes, tone, or implied meaning.
  ```

#### Modelos Instruct
- **Caracter√≠sticas**: Formato de instrucci√≥n estructurado con reglas numeradas y definici√≥n de tarea clara
- **Cu√°ndo usar**: Su modelo est√° ajustado para instrucciones (Instruct, Chat, etc.)
- **Estilo**: Estructurado con reglas, pasos numerados, definiciones claras de entrada/salida
- **Ejemplo** (Run B):
  ```
  You are stage 2 (reasoning) in a multi-stage subtitle translation pipeline.
  - Input: one English subtitle line plus nearby context.
  - Output: ENGLISH ONLY: a clear, unambiguous explanation...
  - Do NOT translate to any target language here.
  
  Subtitle line: {line}
  Context (previous/next lines): {context}
  ```

### Ejemplos en CSV

El CSV incluye filas de ejemplo para cada rol:

1. **`(custom-main-base)`** - Ejemplo de modelo Base para Run B
2. **`(custom-main-instruct)`** - Ejemplo de modelo Instruct para Run B
3. **`(custom-localization-base)`** - Ejemplo de modelo Base para Run E
4. **`(custom-localization-instruct)`** - Ejemplo de modelo Instruct para Run E
5. **`(custom-vision-base)`** - Ejemplo de modelo Base para Vision
6. **`(custom-vision-instruct)`** - Ejemplo de modelo Instruct para Vision

### Agregar Su Propio Modelo

1. **Copie una fila de ejemplo** (p. ej., `(custom-main-instruct)`)
2. **Cambie `model_name`** para que coincida con la subcadena del nombre de archivo de su modelo
3. **Establezca `role`** (`main`, `localization`, o `vision`)
4. **Establezca `target_language`** a uno de estos c√≥digos de localizaci√≥n:
   - `en` - Ingl√©s (para modelos main Run B)
   - `zh-TW` - Chino tradicional (Taiw√°n)
   - `zh-CN` - Chino simplificado (Continental)
   - `ja-JP` - Japon√©s
   - `es-ES` - Espa√±ol
   - U otros c√≥digos de localizaci√≥n IETF seg√∫n sea necesario
5. **Establezca `chat_format`** para que coincida con la plantilla de chat de su modelo:
   - `chatml` - muchos modelos instruct/chat modernos
   - `llama-3` - Modelos Llama 3
   - `mistral-instruct` - Modelos Mistral
   - `moondream` - algunos modelos de visi√≥n
6. **Escriba `system_prompt_template`** (definici√≥n de rol, generalmente 1-2 oraciones)
   - Para modelos de localizaci√≥n: Use `[target_language]` como marcador de posici√≥n si desea que el prompt mencione el idioma objetivo de manera gen√©rica
7. **Escriba `user_prompt_template`** (tarea con marcadores de posici√≥n)
   - Use estilo Base para modelos base
   - Use estilo Instruct para modelos ajustados para instrucciones
   - Para modelos de localizaci√≥n: Reemplace `[target_language]` con el c√≥digo de localizaci√≥n real (p. ej., `zh-TW`, `ja-JP`) en el texto de su prompt
8. **Complete `notes`** (descripci√≥n en ingl√©s)

### Notas Importantes

- **Fronteras de idioma**: **Run A‚ÄìD** (audio, brief v1/v2/v3, visi√≥n): los prompts y la salida del modelo deben ser **solo en ingl√©s**. **Run E** (main_group_translate, local_polish, localization, main_assemble): los prompts est√°n en **ingl√©s**; solo la **salida** (l√≠neas traducidas, sugerencias de frases) est√° en el idioma objetivo. No ponga instrucciones en idioma objetivo (p. ej. chino o japon√©s) en los prompts de Run E‚Äîuse ingl√©s (p. ej. ¬´Output ONLY the translated subtitle in the target language (locale: zh-TW).¬ª) para que el idioma del prompt no se mezcle con el de la salida.
- **Idioma del prompt**: Para Run B/C/D use prompts solo en ingl√©s; para Run E use instrucciones en ingl√©s y espere salida en idioma objetivo del modelo.
- **Formato de chat**: Debe coincidir con la plantilla de chat de su modelo. El formato incorrecto puede causar salida deficiente o errores.
  - **Para modelos de visi√≥n**: El formato de chat lo detecta autom√°ticamente `LocalVisionModel` seg√∫n el nombre del archivo del modelo. El campo `chat_format` del CSV es sobre todo para documentaci√≥n.
- **Marcadores de posici√≥n**: Siempre use los nombres exactos de los marcadores de posici√≥n (`{line}`, `{context}`, `{target_language}`, etc.). Se reemplazan autom√°ticamente.
- **Salida Run B/C/D (brief)**: Debe solicitar JSON con `target_language`, `tl_instruction`, `meaning_tl`, `draft_tl`, `idiom_requests`, `ctx_brief`, referents, tone_note, scene_brief ‚Äî **todo en ingl√©s** (brief neutral). **Un need por etapa**: **v1** solo **`need_vision`**; **v2** solo **`need_multi_frame_vision`**; **v3** solo **`need_more_context`**. Opcional: `plain_en`, `idiom_flag`, `transliteration_requests`, `omit_sfx`; `notes` puede contener PACK para Run E.

---

## Soluci√≥n de Problemas

### "Faltan archivos de modelo requeridos"
Ejecute `start.bat`, abrir√° este README y le dir√° qu√© archivos faltan.

### GPU no detectada o rendimiento lento
Este proyecto incluye **ruedas precompiladas de llama-cpp-python** optimizadas para GPUs NVIDIA (CUDA 12.x) y CPUs Intel.
- **GPUs NVIDIA**: aseg√∫rese de tener instalado el controlador de GPU m√°s reciente. La aplicaci√≥n detectar√° y usar√° CUDA autom√°ticamente.
- **CPUs Intel**: la versi√≥n de CPU est√° optimizada para procesadores Intel modernos y no requiere el conjunto de instrucciones AVX-512.
- **GPUs AMD/Intel Arc**: soporte experimental disponible pero requiere configuraci√≥n manual (no incluido en ruedas precompiladas).

### Advertencia de "symlink" de Windows
Esta advertencia proviene del cach√© de Hugging Face. Como este proyecto ya no descarga modelos autom√°ticamente, puede ignorarla.

### Errores del modelo de audio (Run A)
Run A usa el modelo de Hugging Face **ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition**. Ejecute `pip install -r requirements_base.txt` (torch, transformers, soundfile, scipy). La primera ejecuci√≥n descargar√° el modelo del Hub. La extracci√≥n de audio requiere ffmpeg en PATH.

### ffmpeg no encontrado
- **Windows**: `install.bat` descarga ffmpeg en `runtime\ffmpeg` cuando no est√° en PATH. Si falla, vea **FFMPEG_INSTALL.md** para descarga manual e instalaci√≥n (builds BtbN, winget, o agregar `runtime\ffmpeg\bin` a PATH).
- **Linux / macOS**: `install.sh` no descarga ffmpeg autom√°ticamente; inst√°lelo con su gestor de paquetes y vea **FFMPEG_INSTALL.md** si hace falta.

---

## Licencia/Descargo de Responsabilidad

Esta es una herramienta local. Usted es responsable de la licencia y el uso del modelo.
